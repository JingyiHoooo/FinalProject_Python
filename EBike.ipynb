{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dropbox\n",
    "import datetime\n",
    "import schedule\n",
    "import numpy as np\n",
    "import string\n",
    "import requests\n",
    "\n",
    "from threading import Timer\n",
    "import time\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import csv\n",
    "import sqlite3\n",
    "\n",
    "\n",
    "import math\n",
    "import random\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import matplotlib.dates as mdate\n",
    "\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "\n",
    "\n",
    "import codecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful Downloading database file from Dropbox, overwriting C:\\FINAL_PROJECT\\EBike_Files\\Data.db...\n"
     ]
    },
    {
     "ename": "DatabaseError",
     "evalue": "database disk image is malformed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mDatabaseError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-bfbbe832009b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    101\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[0mschedule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclear\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 103\u001b[1;33m     \u001b[0mEBikeData_Getting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mStartEBike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    104\u001b[0m     \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'here'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-bfbbe832009b>\u001b[0m in \u001b[0;36mStartEBike\u001b[1;34m()\u001b[0m\n\u001b[0;32m     88\u001b[0m         \u001b[0mschedule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminutes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEBikeData_Getting\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEBike\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_t\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_hP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m             \u001b[0mschedule\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_hP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\schedule\\__init__.py\u001b[0m in \u001b[0;36mrun_pending\u001b[1;34m()\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;33m:\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mdefault\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0minstance\u001b[0m \u001b[1;33m<\u001b[0m\u001b[0mdefault_scheduler\u001b[0m\u001b[1;33m>\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \"\"\"\n\u001b[1;32m--> 563\u001b[1;33m     \u001b[0mdefault_scheduler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_pending\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    564\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\schedule\\__init__.py\u001b[0m in \u001b[0;36mrun_pending\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     92\u001b[0m         \u001b[0mrunnable_jobs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjobs\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshould_run\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mjob\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunnable_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 94\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_job\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     95\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mrun_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelay_seconds\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\schedule\\__init__.py\u001b[0m in \u001b[0;36m_run_job\u001b[1;34m(self, job)\u001b[0m\n\u001b[0;32m    145\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_job\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mret\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCancelJob\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mret\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0mCancelJob\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcancel_job\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\schedule\\__init__.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    464\u001b[0m         \"\"\"\n\u001b[0;32m    465\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Running job %s'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 466\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjob_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    467\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlast_run\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_schedule_next_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-3-bfbbe832009b>\u001b[0m in \u001b[0;36mEBike\u001b[1;34m(x_t, y_hP)\u001b[0m\n\u001b[0;32m     37\u001b[0m             \u001b[1;31m#timeframe = '2019-07-19 19:28'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mres_findData\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SELECT * FROM bikeData WHERE time LIKE '%%%s%%'\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[0mtimeframe\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# find \"key words\" in column time of table bikeData\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mcursor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfetchone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# No corresponding data to the time, need Optimize\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDatabaseError\u001b[0m: database disk image is malformed"
     ]
    }
   ],
   "source": [
    "class EBikeData_Getting:\n",
    "        \n",
    "    def EBike(x_t,y_hP):\n",
    "        # Dropbox access token    \n",
    "        dbx = dropbox.Dropbox('lY_d3DAmzgAAAAAAAAAAs2SoAOwHmVVqP5ozJcw4sDBPvIdzSSwISAjUuy1eDLt4')\n",
    "\n",
    "        # Set parameters for downloading the file \n",
    "        # Saving path\n",
    "        save_path = 'C:\\\\FINAL_PROJECT\\\\EBike_Files\\\\Data.db'\n",
    "        # File location in dropbox    \n",
    "        path = '/EBIKE.db'\n",
    "        \n",
    "         # current time\n",
    "        timestamp = datetime.datetime.now()\n",
    "        # time gap\n",
    "        delta = datetime.timedelta(minutes = 1)\n",
    "        # time where the IBI file has been bulit\n",
    "        filetime = timestamp - delta\n",
    "\n",
    "        # Re-formatting: datetime->String\n",
    "        timeframe = filetime.strftime('%Y-%m-%d %H:%M')\n",
    "        #res = dbx.files_list_folder(path,None)\n",
    "        #print (res)\n",
    "        # try download\n",
    "        try:\n",
    "            dbx.files_download_to_file(save_path,path,None)   \n",
    "        except:\n",
    "                print('Database current is not exsit')\n",
    "                pass\n",
    "        else:\n",
    "            print(\"Successful Downloading database file from Dropbox, overwriting \" + save_path + \"...\")\n",
    "    \n",
    "            # Save voltage of the motor and data which averaged\n",
    "            conn = sqlite3.connect(save_path)\n",
    "            cursor = conn.cursor()\n",
    "            \n",
    "            #timeframe = '2019-07-19 19:28'\n",
    "\n",
    "            res_findData=cursor.execute(\"SELECT * FROM bikeData WHERE time LIKE '%%%s%%'\" %timeframe) # find \"key words\" in column time of table bikeData\n",
    "\n",
    "            if cursor.fetchone() is None:   # No corresponding data to the time, need Optimize\n",
    "                print('Not Found')\n",
    "                pass\n",
    "            else:                   # Have such data\n",
    "                rows = cursor.fetchall()\n",
    "\n",
    "                sum_hP = 0\n",
    "                sum_ThrOut = 0\n",
    "                count = 0\n",
    "\n",
    "                for row in rows:\n",
    "                    sum_hP += row[9]\n",
    "                    sum_ThrOut += row[12]\n",
    "                    count += 1\n",
    "\n",
    "            conn.close()\n",
    "\n",
    "            if count == 0:\n",
    "                pass\n",
    "            \n",
    "            else:\n",
    "                ave_hP = sum_hP/count\n",
    "                ave_ThrOut = sum_ThrOut/count\n",
    "                # export the data processed into file \"export_EBikedata.csv\"\n",
    "\n",
    "                x_t.append(timeframe)\n",
    "                y_hP.append(ave_hP)\n",
    "                \n",
    "                fig = HR_Getting.draw(x_t, y_hP)\n",
    "                \n",
    "                with open(\"export_EBikedata.csv\", \"a\", newline='') as f:\n",
    "                    headers = ['time', 'average humanPower', 'average ThrottleOutput' ]\n",
    "                    writer = csv.writer(f)\n",
    "\n",
    "                    if not os.path.getsize(\"export_EBikedata.csv\"):\n",
    "\n",
    "                        # print('no headers')\n",
    "                        writer.writerow(headers) # file doesn't exist yet, write a header\n",
    "                    else:\n",
    "                        # print('have headers')\n",
    "                        writer.writerow([timeframe,ave_hP,ave_ThrOut])\n",
    "                        # Remove duplicates\n",
    "                        # pd.read_csv(\"export_EBikedata.csv\").drop_duplicates(subset =\"First Name\",keep = False, inplace = True)\n",
    "                        f.close()\n",
    "    def StartEBike():\n",
    "        x_t = []\n",
    "        y_hP = []\n",
    "        schedule.every(1).minutes.do(EBikeData_Getting.EBike,x_t,y_hP)\n",
    "        while True:\n",
    "            schedule.run_pending()\n",
    "            \n",
    "    def draw(x_t, y_hP):\n",
    "        plt.clf()\n",
    "        plt.plot(x, y, '-r')\n",
    "        plt.tick_params(axis='x', rotation=90)\n",
    "        plt.title('bpm verus time')\n",
    "        plt.xlabel('time')\n",
    "        plt.ylabel('human power')\n",
    "        plt.pause(0.01)  # pause a bit so that plots are updated\n",
    "            \n",
    "if __name__ == \"__main__\":\n",
    "    schedule.clear()\n",
    "    EBikeData_Getting.StartEBike()\n",
    "    print ('here')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('android_metadata',), ('bikeData',), ('bikeLocation',), ('breathingControl',), ('caloriesControl',), ('commandSent',), ('cooperativeBreathingControl',), ('heartRate',), ('mBandCaloriesBurned',), ('mTarget',), ('motorFilter',), ('sqlite_sequence',), ('trafficLight',)]\n"
     ]
    }
   ],
   "source": [
    "#View the tables inside the Data.db\n",
    "conn = sqlite3.connect( 'C:\\\\FINAL_PROJECT\\\\EBike_Files\\\\Data.db')\n",
    "cursor = conn.cursor()\n",
    "sql = \"\"\"select name from sqlite_master where type='table' order by name\"\"\"\n",
    "cursor.execute(sql)\n",
    "result = cursor.fetchall()\n",
    "print (result)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '_id', 'INTEGER', 0, None, 1), (1, 'time', 'TIMESTAMP', 0, 'CURRENT_TIMESTAMP', 0), (2, 'batteryEnergy', 'FLOAT', 0, None, 0), (3, 'voltage', 'FLOAT', 0, None, 0), (4, 'current', 'FLOAT', 0, None, 0), (5, 'speed', 'FLOAT', 0, None, 0), (6, 'distance', 'FLOAT', 0, None, 0), (7, 'temperature', 'FLOAT', 0, None, 0), (8, 'RPM', 'FLOAT', 0, None, 0), (9, 'humanPower', 'FLOAT', 0, None, 0), (10, 'torque', 'FLOAT', 0, None, 0), (11, 'throttleIn', 'FLOAT', 0, None, 0), (12, 'throttleOut', 'FLOAT', 0, None, 0), (13, 'acceleration', 'FLOAT', 0, None, 0), (14, 'flag', 'STRING', 0, None, 0)]\n"
     ]
    }
   ],
   "source": [
    "# headers of tables in .db file\n",
    "conn = sqlite3.connect( 'C:\\\\FINAL_PROJECT\\\\EBike_Files\\\\Data.db')\n",
    "cursor = conn.cursor()\n",
    "sql = \"\"\"pragma table_info(bikeData)\"\"\"\n",
    "cursor.execute(sql)\n",
    "result = cursor.fetchall()\n",
    "print (result)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save voltage of the motor and data which averaged\n",
    "conn = sqlite3.connect( 'C:\\\\FINAL_PROJECT\\\\EBike_Files\\\\Data.db')\n",
    "cursor = conn.cursor()\n",
    "timeframe = '2019-07-19 19:28'\n",
    "\n",
    "res_findData=cursor.execute(\"SELECT * FROM bikeData WHERE time LIKE '%%%s%%'\" %timeframe) # find \"key words\" in column time of table bikeData\n",
    "\n",
    "if cursor.fetchone() is None:   # No corresponding data to the time, need Optimize\n",
    "    print('Not Found')\n",
    "    pass\n",
    "else:                   # Have such data\n",
    "    rows = cursor.fetchall()\n",
    "    \n",
    "    sum_hP = 0\n",
    "    sum_ThrOut = 0\n",
    "    count = 0\n",
    "        \n",
    "    for row in rows:\n",
    "        sum_hP += row[9]\n",
    "        sum_ThrOut += row[12]\n",
    "        count += 1\n",
    "        \n",
    "conn.close()\n",
    "\n",
    "if count == 0:\n",
    "    pass\n",
    "else:\n",
    "    ave_hP = sum_hP/count\n",
    "    ave_ThrOut = sum_ThrOut/count\n",
    "    # export the data processed into file \"export_EBikedata.csv\"\n",
    "\n",
    "    with open(\"export_EBikedata.csv\", \"a\", newline='') as f:\n",
    "        headers = ['time', 'average humanPower', 'average ThrottleOutput' ]\n",
    "        writer = csv.writer(f)\n",
    "\n",
    "        if not os.path.getsize(\"export_EBikedata.csv\"):\n",
    "            \n",
    "            # print('no headers')\n",
    "            writer.writerow(headers) # file doesn't exist yet, write a header\n",
    "        else:\n",
    "            # print('have headers')\n",
    "            writer.writerow([timeframe,ave_hP,ave_ThrOut])\n",
    "            # Remove duplicates\n",
    "            # pd.read_csv(\"export_EBikedata.csv\").drop_duplicates(subset =\"First Name\",keep = False, inplace = True)\n",
    "            f.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-16 20:10\n"
     ]
    }
   ],
   "source": [
    "        timestamp = datetime.datetime.now()\n",
    "        # time gap\n",
    "        delta = datetime.timedelta(minutes = 1)\n",
    "        # time where the IBI file has been bulit\n",
    "        filetime = timestamp - delta\n",
    "\n",
    "        # Re-formatting: datetime->String\n",
    "        timeframe = filetime.strftime('%Y-%m-%d %H:%M')\n",
    "        print(timeframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileMetadata(name='EBike.db', id='id:HDe7egdlNmAAAAAAAAAJvw', client_modified=datetime.datetime(2019, 8, 16, 18, 47, 5), server_modified=datetime.datetime(2019, 8, 16, 18, 47, 5), rev='01590406aa75a03000000016b5ec0a0', size=17559552, path_lower='/ebike.db', path_display='/EBike.db', parent_shared_folder_id=None, media_info=None, symlink_info=None, sharing_info=None, property_groups=None, has_explicit_shared_members=None, content_hash='d60de019835fc1fb18c1310cc7b7a404a0e53fbd5b739f91b34f1cf36d3ccef3')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        dbx = dropbox.Dropbox('lY_d3DAmzgAAAAAAAAAAs2SoAOwHmVVqP5ozJcw4sDBPvIdzSSwISAjUuy1eDLt4')\n",
    "\n",
    "        # Set parameters for downloading the file \n",
    "        # Saving path\n",
    "        save_path = 'C:\\\\FINAL_PROJECT\\\\EBike_Files\\\\Data.db'\n",
    "        # File location in dropbox    \n",
    "        path = '/EBIKE.db'\n",
    "        #res = dbx.files_list_folder(path,None)\n",
    "        #print (res)\n",
    "        # try download\n",
    "        dbx.files_download_to_file(save_path,path,None)   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
